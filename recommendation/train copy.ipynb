{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-bigquery in /home/bryan/.local/lib/python3.8/site-packages (3.12.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (2.6.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (23.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.21.0 in /usr/lib/python3/dist-packages (from google-cloud-bigquery) (2.22.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.47.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (1.59.0)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.2 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.15.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (1.22.3)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (2.3.3)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (4.24.4)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-bigquery) (2.12.0)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-resumable-media<3.0dev,>=0.6.0->google-cloud-bigquery) (1.5.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil<3.0dev,>=2.7.2->google-cloud-bigquery) (1.14.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-cloud-core<3.0.0dev,>=1.6.0->google-cloud-bigquery) (2.23.3)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /home/bryan/.local/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.61.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2; extra == \"grpc\" in /home/bryan/.local/lib/python3.8/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-bigquery) (1.59.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/bryan/.local/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-core<3.0.0dev,>=1.6.0->google-cloud-bigquery) (5.3.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/bryan/.local/lib/python3.8/site-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-core<3.0.0dev,>=1.6.0->google-cloud-bigquery) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/lib/python3/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-core<3.0.0dev,>=1.6.0->google-cloud-bigquery) (0.2.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/lib/python3/dist-packages (from rsa<5,>=3.1.4->google-auth<3.0dev,>=1.25.0->google-cloud-core<3.0.0dev,>=1.6.0->google-cloud-bigquery) (0.4.2)\n",
      "Requirement already satisfied: db-dtypes in /home/bryan/.local/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: pyarrow>=3.0.0 in /home/bryan/.local/lib/python3.8/site-packages (from db-dtypes) (13.0.0)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /home/bryan/.local/lib/python3.8/site-packages (from db-dtypes) (1.24.4)\n",
      "Requirement already satisfied: pandas>=0.24.2 in /home/bryan/.local/lib/python3.8/site-packages (from db-dtypes) (2.0.3)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/bryan/.local/lib/python3.8/site-packages (from db-dtypes) (23.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/bryan/.local/lib/python3.8/site-packages (from pandas>=0.24.2->db-dtypes) (2023.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bryan/.local/lib/python3.8/site-packages (from pandas>=0.24.2->db-dtypes) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bryan/.local/lib/python3.8/site-packages (from pandas>=0.24.2->db-dtypes) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=0.24.2->db-dtypes) (1.14.0)\n",
      "Requirement already satisfied: tqdm in /home/bryan/.local/lib/python3.8/site-packages (4.66.1)\n",
      "Requirement already satisfied: pyspark in /home/bryan/.local/lib/python3.8/site-packages (3.5.0)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/bryan/.local/lib/python3.8/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: pandas in /home/bryan/.local/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/bryan/.local/lib/python3.8/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.20.3; python_version < \"3.10\" in /home/bryan/.local/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/bryan/.local/lib/python3.8/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/bryan/.local/lib/python3.8/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-bigquery\n",
    "!pip install db-dtypes\n",
    "!pip install tqdm\n",
    "!pip install pyspark\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/jvm/java-11-openjdk-amd64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/10/18 22:50:35 WARN Utils: Your hostname, ubuntu resolves to a loopback address: 127.0.1.1; using 155.246.81.32 instead (on interface eno1)\n",
      "23/10/18 22:50:35 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/10/18 22:50:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pandas as pd\n",
    "import requests\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import os\n",
    "from pyspark.sql import Row\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "\n",
    "\n",
    "print(os.environ[\"JAVA_HOME\"])\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.appName('recommendation_ai').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:KeyboardInterrupt while sending command.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bryan/.local/lib/python3.8/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
      "    response = connection.send_command(command)\n",
      "  File \"/home/bryan/.local/lib/python3.8/site-packages/py4j/clientserver.py\", line 511, in send_command\n",
      "    answer = smart_decode(self.stream.readline()[:-1])\n",
      "  File \"/usr/lib/python3.8/socket.py\", line 669, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "KeyboardInterrupt\n",
      "[Stage 1:>                                                        (0 + 56) / 56]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m likes_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mcsv(\u001b[39m'\u001b[39;49m\u001b[39mlikes.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, inferSchema\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, header\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      2\u001b[0m posts_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mcsv(\u001b[39m'\u001b[39m\u001b[39mposts.csv\u001b[39m\u001b[39m'\u001b[39m, inferSchema\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, header\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m profiles_df \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39mread\u001b[39m.\u001b[39mcsv(\u001b[39m'\u001b[39m\u001b[39mprofiles.csv\u001b[39m\u001b[39m'\u001b[39m, inferSchema\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, header\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pyspark/sql/readwriter.py:740\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m:\n\u001b[1;32m    739\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spark\u001b[39m.\u001b[39m_sc\u001b[39m.\u001b[39m_jvm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 740\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mcsv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_spark\u001b[39m.\u001b[39;49m_sc\u001b[39m.\u001b[39;49m_jvm\u001b[39m.\u001b[39;49mPythonUtils\u001b[39m.\u001b[39;49mtoSeq(path)))\n\u001b[1;32m    741\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    743\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "likes_df = spark.read.csv('likes.csv', inferSchema=True, header=True)\n",
    "posts_df = spark.read.csv('posts.csv', inferSchema=True, header=True)\n",
    "profiles_df = spark.read.csv('profiles.csv', inferSchema=True, header=True)\n",
    "\n",
    "posts_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def get_content(uri1, uri2):\n",
    "    try:\n",
    "        response = requests.get(uri1)\n",
    "        return response.text\n",
    "    except:\n",
    "        try:\n",
    "            response = requests.get(uri2)\n",
    "            return response.text\n",
    "        except:\n",
    "            return \"\"\n",
    "        \n",
    "# Collect the unique URIs to a Python list\n",
    "uri_pairs = posts_df.select('s3_metadata_location', 'content_uri').distinct().rdd.map(tuple).collect()\n",
    "\n",
    "\n",
    "def get_content_pair(uri_pair):\n",
    "    s3_metadata_location, content_uri = uri_pair\n",
    "    content = get_content(content_uri, s3_metadata_location)\n",
    "    return Row(s3_metadata_location=s3_metadata_location, content=content)\n",
    "\n",
    "# Use a ThreadPoolExecutor to parallelize the requests\n",
    "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "    rows = list(tqdm(executor.map(get_content_pair, uri_pairs), total=len(uri_pairs), desc=\"Loading content\"))\n",
    "\n",
    "# Create a DataFrame from the results\n",
    "content_df = spark.createDataFrame(rows)\n",
    "\n",
    "# Join the results back to the original DataFrame\n",
    "posts_df = posts_df.join(content_df, on='s3_metadata_location', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "\n",
    "\n",
    "# Rename the columns to match the names expected by ALS\n",
    "ratings_df = likes_df.selectExpr(\"actioned_by_profile_id as userId\", \"publication_id as postId\", \"reaction as rating\")\n",
    "\n",
    "\n",
    "\n",
    "# Create a StringIndexer\n",
    "indexer = StringIndexer(inputCol=\"userId\", outputCol=\"userIdIndex\")\n",
    "\n",
    "# Index the userId column\n",
    "ratings_df = indexer.fit(ratings_df).transform(ratings_df)\n",
    "\n",
    "# Do the same for the postId column\n",
    "indexer.setInputCol(\"postId\")\n",
    "indexer.setOutputCol(\"postIdIndex\")\n",
    "ratings_df = indexer.fit(ratings_df).transform(ratings_df)\n",
    "\n",
    "\n",
    "\n",
    "ratings_df = ratings_df.filter(ratings_df.userId.isNotNull())\n",
    "\n",
    "# Map \"UPVOTE\" to 1 and \"DOWNVOTE\" to -1\n",
    "ratings_df = ratings_df.withColumn(\"rating\", when(col(\"rating\") == \"UPVOTE\", 1).otherwise(-1))\n",
    "\n",
    "ratings_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "# Assume you have a DataFrame `ratings_df` with columns 'userId', 'postId', and 'rating'\n",
    "# Split the data into training and test sets\n",
    "(training, test) = ratings_df.randomSplit([0.8, 0.2])\n",
    "# Create an ALS model\n",
    "als = ALS(maxIter=5, regParam=0.01, userCol=\"userIdIndex\", itemCol=\"postIdIndex\", ratingCol=\"rating\",\n",
    "          coldStartStrategy=\"drop\")\n",
    "\n",
    "# Train the ALS model\n",
    "model = als.fit(training)\n",
    "\n",
    "# Make predictions on the test data\n",
    "predictions = model.transform(test)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"rating\", predictionCol=\"prediction\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error = {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate top 10 post recommendations for each user\n",
    "userRecs = model.recommendForAllUsers(10)\n",
    "\n",
    "userRecs.show()\n",
    "\n",
    "# Convert the recommendations array to a string\n",
    "userRecs = userRecs.withColumn(\"recommendations\", col(\"recommendations\").cast(\"string\"))\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "userRecs.write.csv(\"user_recommendations.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
